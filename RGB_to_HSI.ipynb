{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "IMPORTING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "\n",
        "from operator import truediv\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "# !pip install spectral\n",
        "import spectral\n",
        "import mat73\n",
        "import tensorflow \n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LOADING DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        " \n",
        "data_dict = {\n",
        "        'data':('data (1).mat','data (2).mat','data (3).mat','data (4).mat')\n",
        "    }\n",
        "p=(X_1, X_2, X_3, X_4) = data_dict.get('data')\n",
        "# l_rgb,l_rad=[],[]\n",
        "# for i in p:\n",
        "#     l_rgb.append(mat73.loadmat(i)['rgb'])\n",
        "#     l_rad.append(mat73.loadmat(i)['rad'])\n",
        "x=mat73.loadmat(X_1)['rgb']\n",
        "y=mat73.loadmat(X_1)['rad']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TEST DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "test=mat73.loadmat(X_4)['rgb']\n",
        "test=np.resize(test,(64,64,3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 1, 64, 64, 3)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "test = np.expand_dims(test, axis=0) \n",
        "test = np.expand_dims(test, axis=0) \n",
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[[ 190.875     ,  191.44444444,  190.75      , ...,\n",
              "            190.25      ,  188.375     ,  189.25      ],\n",
              "          [ 190.5       ,  190.55555556,  190.875     , ...,\n",
              "            189.875     ,  189.625     ,  190.25      ],\n",
              "          [ 210.        ,  226.22222222,  244.375     , ...,\n",
              "            346.125     ,  378.625     ,  577.5       ],\n",
              "          ...,\n",
              "          [ 209.75      ,  223.        ,  234.75      , ...,\n",
              "            502.75      ,  535.625     ,  781.25      ],\n",
              "          [ 211.125     ,  223.11111111,  238.875     , ...,\n",
              "            452.125     ,  490.625     ,  716.375     ],\n",
              "          [ 211.125     ,  222.77777778,  240.125     , ...,\n",
              "            384.75      ,  417.75      ,  617.375     ]],\n",
              "\n",
              "         [[ 211.        ,  222.66666667,  240.75      , ...,\n",
              "            384.125     ,  414.5       ,  628.5       ],\n",
              "          [ 209.5       ,  225.66666667,  241.125     , ...,\n",
              "            409.        ,  434.625     ,  664.25      ],\n",
              "          [ 211.        ,  224.55555556,  242.5       , ...,\n",
              "            427.5       ,  456.375     ,  695.125     ],\n",
              "          ...,\n",
              "          [ 216.75      ,  237.11111111,  267.625     , ...,\n",
              "            532.875     ,  569.625     ,  845.5       ],\n",
              "          [ 218.625     ,  243.22222222,  277.75      , ...,\n",
              "            602.375     ,  639.125     ,  925.625     ],\n",
              "          [ 215.125     ,  246.77777778,  280.875     , ...,\n",
              "            630.125     ,  652.5       ,  926.125     ]],\n",
              "\n",
              "         [[ 217.125     ,  244.22222222,  276.        , ...,\n",
              "            493.25      ,  533.75      ,  781.25      ],\n",
              "          [ 217.125     ,  238.        ,  255.375     , ...,\n",
              "            409.75      ,  450.        ,  682.75      ],\n",
              "          [ 213.625     ,  229.88888889,  243.25      , ...,\n",
              "            389.125     ,  432.25      ,  663.375     ],\n",
              "          ...,\n",
              "          [ 238.625     ,  289.33333333,  350.625     , ...,\n",
              "           1187.5       , 1150.625     , 1345.        ],\n",
              "          [ 241.625     ,  293.33333333,  350.875     , ...,\n",
              "           1205.        , 1168.75      , 1357.375     ],\n",
              "          [ 243.5       ,  291.66666667,  353.75      , ...,\n",
              "           1263.125     , 1215.75      , 1381.5       ]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 268.        ,  343.77777778,  412.875     , ...,\n",
              "           1022.        ,  936.875     ,  974.75      ],\n",
              "          [ 269.125     ,  347.33333333,  413.875     , ...,\n",
              "           1035.375     ,  934.125     ,  970.75      ],\n",
              "          [ 269.125     ,  349.11111111,  415.625     , ...,\n",
              "           1029.375     ,  938.125     ,  979.625     ],\n",
              "          ...,\n",
              "          [ 271.125     ,  352.55555556,  419.5       , ...,\n",
              "           1098.375     ,  997.875     , 1032.        ],\n",
              "          [ 276.125     ,  353.77777778,  426.125     , ...,\n",
              "           1092.25      ,  992.5       , 1030.125     ],\n",
              "          [ 272.875     ,  348.88888889,  421.        , ...,\n",
              "           1091.625     ,  998.875     , 1034.        ]],\n",
              "\n",
              "         [[ 271.25      ,  353.88888889,  423.25      , ...,\n",
              "           1096.5       ,  992.625     , 1028.5       ],\n",
              "          [ 270.625     ,  352.11111111,  418.75      , ...,\n",
              "           1106.75      ,  997.125     , 1027.375     ],\n",
              "          [ 269.625     ,  351.66666667,  421.        , ...,\n",
              "           1106.25      ,  991.875     , 1035.625     ],\n",
              "          ...,\n",
              "          [ 268.5       ,  337.88888889,  397.75      , ...,\n",
              "           1005.375     ,  906.25      ,  940.        ],\n",
              "          [ 268.5       ,  337.        ,  398.        , ...,\n",
              "           1002.625     ,  911.375     ,  942.        ],\n",
              "          [ 267.375     ,  338.88888889,  400.25      , ...,\n",
              "            995.375     ,  909.25      ,  944.625     ]],\n",
              "\n",
              "         [[ 266.75      ,  342.22222222,  396.625     , ...,\n",
              "            997.        ,  912.75      ,  940.75      ],\n",
              "          [ 268.5       ,  343.55555556,  406.75      , ...,\n",
              "            996.5       ,  914.125     ,  941.375     ],\n",
              "          [ 268.        ,  342.66666667,  403.625     , ...,\n",
              "           1006.125     ,  916.5       ,  944.875     ],\n",
              "          ...,\n",
              "          [ 444.125     ,  657.        ,  769.75      , ...,\n",
              "            754.        ,  657.25      ,  654.25      ],\n",
              "          [ 444.125     ,  657.22222222,  784.125     , ...,\n",
              "            753.875     ,  664.375     ,  657.        ],\n",
              "          [ 448.875     ,  650.55555556,  776.75      , ...,\n",
              "            752.875     ,  661.        ,  655.125     ]]]]])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_y=mat73.loadmat(X_4)['rad']\n",
        "test_y=np.resize(test_y,(64,64,31))\n",
        "test_y=np.expand_dims(test_y,axis=0)\n",
        "test_y=np.expand_dims(test_y,axis=0)\n",
        "test_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TRAIN DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1392, 1306, 3) (1300, 1392, 31)\n"
          ]
        }
      ],
      "source": [
        "print(x.shape, y.shape)\n",
        "train=x\n",
        "valid=y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 3) (64, 64, 31)\n"
          ]
        }
      ],
      "source": [
        "t=np.resize(x,(64,64,3))\n",
        "v=np.resize(y,(64,64,31))\n",
        "# t=np.reshape(t,(1,t.shape[0],t.shape[1],t.shape[2]))\n",
        "# v=np.reshape(v,(1,v.shape[0],v.shape[1],v.shape[2]))\n",
        "\n",
        "print(t.shape,v.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "INCRESASING DIMENSIONS TO MATCH WITH NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1, 1, 64, 64, 3), (1, 1, 64, 64, 31))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = np.expand_dims(t, axis=0) \n",
        "v= np.expand_dims(v,axis=0)\n",
        "t = np.expand_dims(t, axis=0) \n",
        "v= np.expand_dims(v,axis=0)\n",
        "(t.shape,v.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BP-NET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Conv3D\n",
        "from keras.layers import Dense\n",
        "\n",
        "#making the BP-net\n",
        "\n",
        "cnn = keras.Sequential()\n",
        "cnn.add(Conv3D(32,(3,5,5), activation='relu', input_shape=(1,64,64,3),padding='same',use_bias=True))\n",
        "cnn.add(Conv3D(32, 3, activation='relu', input_shape=(32,64,64,3), padding='same', use_bias=True))\n",
        "cnn.add(Conv3D(31,3, activation='relu', input_shape=(32,64,64,3), padding='same', use_bias=True))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/310\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 106792.4766 - accuracy: 0.1294\n",
            "Epoch 2/310\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 80746.1328 - accuracy: 0.0447\n",
            "Epoch 3/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 65683.6328 - accuracy: 0.0854\n",
            "Epoch 4/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 56920.9961 - accuracy: 0.1262\n",
            "Epoch 5/310\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 52519.2930 - accuracy: 0.2217\n",
            "Epoch 6/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 48032.2812 - accuracy: 0.3057\n",
            "Epoch 7/310\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 44634.0547 - accuracy: 0.3379\n",
            "Epoch 8/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 42739.9492 - accuracy: 0.3535\n",
            "Epoch 9/310\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 41593.1562 - accuracy: 0.3052\n",
            "Epoch 10/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 39865.7227 - accuracy: 0.2322\n",
            "Epoch 11/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 38288.1484 - accuracy: 0.1548\n",
            "Epoch 12/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37953.7891 - accuracy: 0.1030\n",
            "Epoch 13/310\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 37853.7969 - accuracy: 0.0659\n",
            "Epoch 14/310\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 37781.4844 - accuracy: 0.0386\n",
            "Epoch 15/310\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 37716.6562 - accuracy: 0.0242\n",
            "Epoch 16/310\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 37656.3320 - accuracy: 0.0122\n",
            "Epoch 17/310\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 37600.1094 - accuracy: 0.0042\n",
            "Epoch 18/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37551.4375 - accuracy: 0.0044\n",
            "Epoch 19/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37510.9766 - accuracy: 0.0063\n",
            "Epoch 20/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37479.0234 - accuracy: 0.0112\n",
            "Epoch 21/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37454.6562 - accuracy: 0.0144\n",
            "Epoch 22/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37436.0547 - accuracy: 0.0142\n",
            "Epoch 23/310\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 37420.8164 - accuracy: 0.0142\n",
            "Epoch 24/310\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 37406.9375 - accuracy: 0.0144\n",
            "Epoch 25/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37393.2617 - accuracy: 0.0139\n",
            "Epoch 26/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37379.3594 - accuracy: 0.0134\n",
            "Epoch 27/310\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 37365.3359 - accuracy: 0.0132\n",
            "Epoch 28/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37351.5391 - accuracy: 0.0122\n",
            "Epoch 29/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37338.3477 - accuracy: 0.0115\n",
            "Epoch 30/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37326.0898 - accuracy: 0.0090\n",
            "Epoch 31/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37314.9453 - accuracy: 0.0076\n",
            "Epoch 32/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37304.9688 - accuracy: 0.0061\n",
            "Epoch 33/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37296.1016 - accuracy: 0.0063\n",
            "Epoch 34/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37288.2500 - accuracy: 0.0054\n",
            "Epoch 35/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37281.3125 - accuracy: 0.0049\n",
            "Epoch 36/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37275.1641 - accuracy: 0.0039\n",
            "Epoch 37/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37269.7500 - accuracy: 0.0042\n",
            "Epoch 38/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37264.9766 - accuracy: 0.0088\n",
            "Epoch 39/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37260.8125 - accuracy: 0.0151\n",
            "Epoch 40/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37257.2344 - accuracy: 0.0227\n",
            "Epoch 41/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37254.1836 - accuracy: 0.0378\n",
            "Epoch 42/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37251.6406 - accuracy: 0.0500\n",
            "Epoch 43/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37249.5391 - accuracy: 0.0684\n",
            "Epoch 44/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37247.8164 - accuracy: 0.0991\n",
            "Epoch 45/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37246.3789 - accuracy: 0.1360\n",
            "Epoch 46/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37245.1562 - accuracy: 0.1624\n",
            "Epoch 47/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37244.0664 - accuracy: 0.1912\n",
            "Epoch 48/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37243.0547 - accuracy: 0.2107\n",
            "Epoch 49/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37242.0703 - accuracy: 0.2271\n",
            "Epoch 50/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37241.0898 - accuracy: 0.2410\n",
            "Epoch 51/310\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 37240.1289 - accuracy: 0.2544\n",
            "Epoch 52/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37239.1719 - accuracy: 0.2695\n",
            "Epoch 53/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37238.2461 - accuracy: 0.2817\n",
            "Epoch 54/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37237.3438 - accuracy: 0.2927\n",
            "Epoch 55/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37236.4766 - accuracy: 0.2959\n",
            "Epoch 56/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37235.6445 - accuracy: 0.3037\n",
            "Epoch 57/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37234.8359 - accuracy: 0.3059\n",
            "Epoch 58/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37234.0625 - accuracy: 0.3091\n",
            "Epoch 59/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37233.3047 - accuracy: 0.3105\n",
            "Epoch 60/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37232.5781 - accuracy: 0.3113\n",
            "Epoch 61/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37231.8906 - accuracy: 0.3105\n",
            "Epoch 62/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37231.2422 - accuracy: 0.3081\n",
            "Epoch 63/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37230.6523 - accuracy: 0.3052\n",
            "Epoch 64/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37230.1250 - accuracy: 0.2998\n",
            "Epoch 65/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37229.6641 - accuracy: 0.2981\n",
            "Epoch 66/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37229.2656 - accuracy: 0.2942\n",
            "Epoch 67/310\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 37228.9297 - accuracy: 0.2925\n",
            "Epoch 68/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37228.6406 - accuracy: 0.2898\n",
            "Epoch 69/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37228.3828 - accuracy: 0.2844\n",
            "Epoch 70/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37228.1562 - accuracy: 0.2808\n",
            "Epoch 71/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37227.9297 - accuracy: 0.2812\n",
            "Epoch 72/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37227.7266 - accuracy: 0.2783\n",
            "Epoch 73/310\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 37227.5234 - accuracy: 0.2764\n",
            "Epoch 74/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37227.3281 - accuracy: 0.2729\n",
            "Epoch 75/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37227.1367 - accuracy: 0.2727\n",
            "Epoch 76/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37226.9688 - accuracy: 0.2710\n",
            "Epoch 77/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37226.7930 - accuracy: 0.2717\n",
            "Epoch 78/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37226.6367 - accuracy: 0.2727\n",
            "Epoch 79/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37226.4844 - accuracy: 0.2712\n",
            "Epoch 80/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37226.3359 - accuracy: 0.2720\n",
            "Epoch 81/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37226.1953 - accuracy: 0.2712\n",
            "Epoch 82/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37226.0430 - accuracy: 0.2720\n",
            "Epoch 83/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37225.8984 - accuracy: 0.2734\n",
            "Epoch 84/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37225.7461 - accuracy: 0.2727\n",
            "Epoch 85/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37225.5938 - accuracy: 0.2734\n",
            "Epoch 86/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37225.4609 - accuracy: 0.2725\n",
            "Epoch 87/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37225.3086 - accuracy: 0.2759\n",
            "Epoch 88/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37225.1641 - accuracy: 0.2781\n",
            "Epoch 89/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37225.0312 - accuracy: 0.2791\n",
            "Epoch 90/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37224.8984 - accuracy: 0.2793\n",
            "Epoch 91/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37224.7656 - accuracy: 0.2803\n",
            "Epoch 92/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37224.6328 - accuracy: 0.2800\n",
            "Epoch 93/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37224.5039 - accuracy: 0.2808\n",
            "Epoch 94/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37224.3672 - accuracy: 0.2815\n",
            "Epoch 95/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37224.2344 - accuracy: 0.2812\n",
            "Epoch 96/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37224.1172 - accuracy: 0.2791\n",
            "Epoch 97/310\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 37223.9883 - accuracy: 0.2798\n",
            "Epoch 98/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37223.8672 - accuracy: 0.2781\n",
            "Epoch 99/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37223.7500 - accuracy: 0.2781\n",
            "Epoch 100/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37223.6328 - accuracy: 0.2788\n",
            "Epoch 101/310\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 37223.5156 - accuracy: 0.2803\n",
            "Epoch 102/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37223.4023 - accuracy: 0.2815\n",
            "Epoch 103/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37223.2930 - accuracy: 0.2817\n",
            "Epoch 104/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37223.1797 - accuracy: 0.2830\n",
            "Epoch 105/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37223.0703 - accuracy: 0.2827\n",
            "Epoch 106/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37222.9688 - accuracy: 0.2832\n",
            "Epoch 107/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37222.8516 - accuracy: 0.2830\n",
            "Epoch 108/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37222.7422 - accuracy: 0.2832\n",
            "Epoch 109/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37222.6406 - accuracy: 0.2854\n",
            "Epoch 110/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37222.5391 - accuracy: 0.2864\n",
            "Epoch 111/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37222.4336 - accuracy: 0.2876\n",
            "Epoch 112/310\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 37222.3359 - accuracy: 0.2896\n",
            "Epoch 113/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37222.2383 - accuracy: 0.2915\n",
            "Epoch 114/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37222.1328 - accuracy: 0.2927\n",
            "Epoch 115/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37222.0391 - accuracy: 0.2942\n",
            "Epoch 116/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37221.9414 - accuracy: 0.2959\n",
            "Epoch 117/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37221.8438 - accuracy: 0.2957\n",
            "Epoch 118/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37221.7422 - accuracy: 0.2959\n",
            "Epoch 119/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37221.6484 - accuracy: 0.2966\n",
            "Epoch 120/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37221.5547 - accuracy: 0.2971\n",
            "Epoch 121/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37221.4570 - accuracy: 0.2971\n",
            "Epoch 122/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37221.3672 - accuracy: 0.2974\n",
            "Epoch 123/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37221.2812 - accuracy: 0.2971\n",
            "Epoch 124/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37221.1875 - accuracy: 0.2974\n",
            "Epoch 125/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37221.0938 - accuracy: 0.2979\n",
            "Epoch 126/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37221.0078 - accuracy: 0.2981\n",
            "Epoch 127/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37220.9180 - accuracy: 0.2979\n",
            "Epoch 128/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37220.8281 - accuracy: 0.2979\n",
            "Epoch 129/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37220.7422 - accuracy: 0.2976\n",
            "Epoch 130/310\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 37220.6562 - accuracy: 0.2983\n",
            "Epoch 131/310\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 37220.5664 - accuracy: 0.2986\n",
            "Epoch 132/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37220.4844 - accuracy: 0.2979\n",
            "Epoch 133/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37220.4062 - accuracy: 0.2976\n",
            "Epoch 134/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37220.3203 - accuracy: 0.2974\n",
            "Epoch 135/310\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 37220.2383 - accuracy: 0.2976\n",
            "Epoch 136/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37220.1562 - accuracy: 0.2971\n",
            "Epoch 137/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37220.0781 - accuracy: 0.2974\n",
            "Epoch 138/310\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 37220.0000 - accuracy: 0.2971\n",
            "Epoch 139/310\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 37219.9219 - accuracy: 0.2983\n",
            "Epoch 140/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37219.8438 - accuracy: 0.2976\n",
            "Epoch 141/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37219.7656 - accuracy: 0.2986\n",
            "Epoch 142/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37219.6875 - accuracy: 0.2993\n",
            "Epoch 143/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37219.6094 - accuracy: 0.2988\n",
            "Epoch 144/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37219.5352 - accuracy: 0.2993\n",
            "Epoch 145/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37219.4609 - accuracy: 0.2998\n",
            "Epoch 146/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37219.3906 - accuracy: 0.3003\n",
            "Epoch 147/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37219.3125 - accuracy: 0.3000\n",
            "Epoch 148/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37219.2422 - accuracy: 0.2998\n",
            "Epoch 149/310\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 37219.1719 - accuracy: 0.3000\n",
            "Epoch 150/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37219.0977 - accuracy: 0.3008\n",
            "Epoch 151/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37219.0312 - accuracy: 0.3015\n",
            "Epoch 152/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37218.9609 - accuracy: 0.3027\n",
            "Epoch 153/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37218.8945 - accuracy: 0.3040\n",
            "Epoch 154/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37218.8242 - accuracy: 0.3042\n",
            "Epoch 155/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37218.7539 - accuracy: 0.3047\n",
            "Epoch 156/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37218.6953 - accuracy: 0.3052\n",
            "Epoch 157/310\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 37218.6250 - accuracy: 0.3054\n",
            "Epoch 158/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37218.5586 - accuracy: 0.3054\n",
            "Epoch 159/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37218.4961 - accuracy: 0.3064\n",
            "Epoch 160/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37218.4375 - accuracy: 0.3071\n",
            "Epoch 161/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37218.3711 - accuracy: 0.3079\n",
            "Epoch 162/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37218.3047 - accuracy: 0.3091\n",
            "Epoch 163/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37218.2422 - accuracy: 0.3093\n",
            "Epoch 164/310\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 37218.1797 - accuracy: 0.3093\n",
            "Epoch 165/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37218.1172 - accuracy: 0.3108\n",
            "Epoch 166/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37218.0625 - accuracy: 0.3098\n",
            "Epoch 167/310\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 37218.0000 - accuracy: 0.3098\n",
            "Epoch 168/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37217.9375 - accuracy: 0.3101\n",
            "Epoch 169/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37217.8828 - accuracy: 0.3101\n",
            "Epoch 170/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37217.8203 - accuracy: 0.3101\n",
            "Epoch 171/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37217.7656 - accuracy: 0.3103\n",
            "Epoch 172/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37217.7109 - accuracy: 0.3108\n",
            "Epoch 173/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37217.6562 - accuracy: 0.3108\n",
            "Epoch 174/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37217.5977 - accuracy: 0.3110\n",
            "Epoch 175/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37217.5469 - accuracy: 0.3110\n",
            "Epoch 176/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37217.4922 - accuracy: 0.3115\n",
            "Epoch 177/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37217.4336 - accuracy: 0.3113\n",
            "Epoch 178/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37217.3828 - accuracy: 0.3123\n",
            "Epoch 179/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37217.3281 - accuracy: 0.3145\n",
            "Epoch 180/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37217.2812 - accuracy: 0.3140\n",
            "Epoch 181/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37217.2266 - accuracy: 0.3132\n",
            "Epoch 182/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37217.1758 - accuracy: 0.3137\n",
            "Epoch 183/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37217.1250 - accuracy: 0.3142\n",
            "Epoch 184/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37217.0781 - accuracy: 0.3145\n",
            "Epoch 185/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37217.0234 - accuracy: 0.3145\n",
            "Epoch 186/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37216.9766 - accuracy: 0.3147\n",
            "Epoch 187/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37216.9258 - accuracy: 0.3154\n",
            "Epoch 188/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37216.8789 - accuracy: 0.3162\n",
            "Epoch 189/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37216.8320 - accuracy: 0.3159\n",
            "Epoch 190/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37216.7852 - accuracy: 0.3169\n",
            "Epoch 191/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37216.7383 - accuracy: 0.3174\n",
            "Epoch 192/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37216.6914 - accuracy: 0.3181\n",
            "Epoch 193/310\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 37216.6484 - accuracy: 0.3179\n",
            "Epoch 194/310\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 37216.6016 - accuracy: 0.3179\n",
            "Epoch 195/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37216.5586 - accuracy: 0.3179\n",
            "Epoch 196/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37216.5156 - accuracy: 0.3179\n",
            "Epoch 197/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37216.4688 - accuracy: 0.3188\n",
            "Epoch 198/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37216.4258 - accuracy: 0.3184\n",
            "Epoch 199/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37216.3828 - accuracy: 0.3176\n",
            "Epoch 200/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37216.3398 - accuracy: 0.3184\n",
            "Epoch 201/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37216.3008 - accuracy: 0.3176\n",
            "Epoch 202/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37216.2617 - accuracy: 0.3176\n",
            "Epoch 203/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37216.2188 - accuracy: 0.3184\n",
            "Epoch 204/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37216.1758 - accuracy: 0.3186\n",
            "Epoch 205/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37216.1406 - accuracy: 0.3184\n",
            "Epoch 206/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37216.0977 - accuracy: 0.3184\n",
            "Epoch 207/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37216.0586 - accuracy: 0.3181\n",
            "Epoch 208/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37216.0195 - accuracy: 0.3186\n",
            "Epoch 209/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37215.9844 - accuracy: 0.3193\n",
            "Epoch 210/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37215.9453 - accuracy: 0.3193\n",
            "Epoch 211/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37215.9102 - accuracy: 0.3193\n",
            "Epoch 212/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37215.8750 - accuracy: 0.3188\n",
            "Epoch 213/310\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 37215.8359 - accuracy: 0.3191\n",
            "Epoch 214/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37215.8047 - accuracy: 0.3193\n",
            "Epoch 215/310\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 37215.7656 - accuracy: 0.3193\n",
            "Epoch 216/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37215.7266 - accuracy: 0.3201\n",
            "Epoch 217/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37215.6992 - accuracy: 0.3196\n",
            "Epoch 218/310\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 37215.6641 - accuracy: 0.3208\n",
            "Epoch 219/310\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 37215.6250 - accuracy: 0.3208\n",
            "Epoch 220/310\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 37215.5938 - accuracy: 0.3210\n",
            "Epoch 221/310\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 37215.5625 - accuracy: 0.3210\n",
            "Epoch 222/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37215.5273 - accuracy: 0.3218\n",
            "Epoch 223/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37215.4922 - accuracy: 0.3215\n",
            "Epoch 224/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37215.4688 - accuracy: 0.3208\n",
            "Epoch 225/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37215.4375 - accuracy: 0.3213\n",
            "Epoch 226/310\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 37215.4023 - accuracy: 0.3213\n",
            "Epoch 227/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37215.3750 - accuracy: 0.3206\n",
            "Epoch 228/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37215.3438 - accuracy: 0.3208\n",
            "Epoch 229/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37215.3125 - accuracy: 0.3210\n",
            "Epoch 230/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37215.2812 - accuracy: 0.3210\n",
            "Epoch 231/310\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 37215.2578 - accuracy: 0.3210\n",
            "Epoch 232/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37215.2266 - accuracy: 0.3218\n",
            "Epoch 233/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37215.1953 - accuracy: 0.3215\n",
            "Epoch 234/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37215.1641 - accuracy: 0.3215\n",
            "Epoch 235/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37215.1406 - accuracy: 0.3223\n",
            "Epoch 236/310\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 37215.1094 - accuracy: 0.3220\n",
            "Epoch 237/310\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 37215.0781 - accuracy: 0.3220\n",
            "Epoch 238/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37215.0586 - accuracy: 0.3215\n",
            "Epoch 239/310\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 37215.0312 - accuracy: 0.3210\n",
            "Epoch 240/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37215.0000 - accuracy: 0.3210\n",
            "Epoch 241/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37214.9727 - accuracy: 0.3210\n",
            "Epoch 242/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37214.9492 - accuracy: 0.3213\n",
            "Epoch 243/310\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 37214.9258 - accuracy: 0.3213\n",
            "Epoch 244/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37214.8984 - accuracy: 0.3215\n",
            "Epoch 245/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37214.8750 - accuracy: 0.3215\n",
            "Epoch 246/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37214.8477 - accuracy: 0.3215\n",
            "Epoch 247/310\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 37214.8242 - accuracy: 0.3215\n",
            "Epoch 248/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37214.7969 - accuracy: 0.3218\n",
            "Epoch 249/310\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 37214.7734 - accuracy: 0.3218\n",
            "Epoch 250/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37214.7500 - accuracy: 0.3215\n",
            "Epoch 251/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37214.7266 - accuracy: 0.3208\n",
            "Epoch 252/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37214.7070 - accuracy: 0.3210\n",
            "Epoch 253/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37214.6836 - accuracy: 0.3215\n",
            "Epoch 254/310\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 37214.6602 - accuracy: 0.3213\n",
            "Epoch 255/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37214.6406 - accuracy: 0.3218\n",
            "Epoch 256/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37214.6172 - accuracy: 0.3218\n",
            "Epoch 257/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37214.5977 - accuracy: 0.3218\n",
            "Epoch 258/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37214.5742 - accuracy: 0.3215\n",
            "Epoch 259/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37214.5547 - accuracy: 0.3220\n",
            "Epoch 260/310\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 37214.5312 - accuracy: 0.3220\n",
            "Epoch 261/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37214.5117 - accuracy: 0.3232\n",
            "Epoch 262/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37214.4922 - accuracy: 0.3237\n",
            "Epoch 263/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37214.4688 - accuracy: 0.3240\n",
            "Epoch 264/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37214.4453 - accuracy: 0.3242\n",
            "Epoch 265/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37214.4297 - accuracy: 0.3242\n",
            "Epoch 266/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37214.4062 - accuracy: 0.3240\n",
            "Epoch 267/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37214.3867 - accuracy: 0.3245\n",
            "Epoch 268/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37214.3672 - accuracy: 0.3247\n",
            "Epoch 269/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37214.3477 - accuracy: 0.3252\n",
            "Epoch 270/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37214.3281 - accuracy: 0.3259\n",
            "Epoch 271/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37214.3125 - accuracy: 0.3267\n",
            "Epoch 272/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37214.2891 - accuracy: 0.3274\n",
            "Epoch 273/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37214.2734 - accuracy: 0.3274\n",
            "Epoch 274/310\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 37214.2539 - accuracy: 0.3274\n",
            "Epoch 275/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37214.2383 - accuracy: 0.3274\n",
            "Epoch 276/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37214.2188 - accuracy: 0.3274\n",
            "Epoch 277/310\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37214.2031 - accuracy: 0.3276\n",
            "Epoch 278/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37214.1875 - accuracy: 0.3279\n",
            "Epoch 279/310\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 37214.1641 - accuracy: 0.3284\n",
            "Epoch 280/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37214.1484 - accuracy: 0.3284\n",
            "Epoch 281/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37214.1328 - accuracy: 0.3281\n",
            "Epoch 282/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37214.1172 - accuracy: 0.3284\n",
            "Epoch 283/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37214.0977 - accuracy: 0.3289\n",
            "Epoch 284/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37214.0820 - accuracy: 0.3289\n",
            "Epoch 285/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37214.0664 - accuracy: 0.3291\n",
            "Epoch 286/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37214.0508 - accuracy: 0.3291\n",
            "Epoch 287/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37214.0391 - accuracy: 0.3293\n",
            "Epoch 288/310\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 37214.0195 - accuracy: 0.3296\n",
            "Epoch 289/310\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 37214.0039 - accuracy: 0.3298\n",
            "Epoch 290/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37213.9844 - accuracy: 0.3298\n",
            "Epoch 291/310\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37213.9688 - accuracy: 0.3301\n",
            "Epoch 292/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37213.9570 - accuracy: 0.3303\n",
            "Epoch 293/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37213.9414 - accuracy: 0.3301\n",
            "Epoch 294/310\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 37213.9297 - accuracy: 0.3303\n",
            "Epoch 295/310\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 37213.9141 - accuracy: 0.3306\n",
            "Epoch 296/310\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 37213.8945 - accuracy: 0.3308\n",
            "Epoch 297/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37213.8828 - accuracy: 0.3313\n",
            "Epoch 298/310\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 37213.8711 - accuracy: 0.3320\n",
            "Epoch 299/310\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 37213.8516 - accuracy: 0.3320\n",
            "Epoch 300/310\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 37213.8359 - accuracy: 0.3323\n",
            "Epoch 301/310\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37213.8242 - accuracy: 0.3323\n",
            "Epoch 302/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37213.8125 - accuracy: 0.3323\n",
            "Epoch 303/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37213.7969 - accuracy: 0.3323\n",
            "Epoch 304/310\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 37213.7812 - accuracy: 0.3323\n",
            "Epoch 305/310\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37213.7695 - accuracy: 0.3325\n",
            "Epoch 306/310\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37213.7578 - accuracy: 0.3320\n",
            "Epoch 307/310\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 37213.7422 - accuracy: 0.3320\n",
            "Epoch 308/310\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37213.7266 - accuracy: 0.3325\n",
            "Epoch 309/310\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37213.7109 - accuracy: 0.3325\n",
            "Epoch 310/310\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37213.6992 - accuracy: 0.3335\n"
          ]
        }
      ],
      "source": [
        "# from tensorflow.keras.optimizers import SGD\n",
        "# opt = SGD(lr=0.001, momentum=0.9)\n",
        "\n",
        "cnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "h = cnn.fit(x=t, y=v, epochs=310)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 1, 64, 64, 32)     7232      \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 1, 64, 64, 32)     27680     \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 1, 64, 64, 31)     26815     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61,727\n",
            "Trainable params: 61,727\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PREDICTING HSI.mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[[0.10742501, 0.12843424, 0.14042543, ..., 0.12420771,\n",
              "           0.1797657 , 0.18268986],\n",
              "          [0.17955106, 0.18829109, 0.21023706, ..., 0.26312104,\n",
              "           0.3143071 , 0.2935715 ],\n",
              "          [0.22086838, 0.20294634, 0.25418198, ..., 0.33347008,\n",
              "           0.37949476, 0.34533176],\n",
              "          ...,\n",
              "          [0.23838033, 0.21231508, 0.27526075, ..., 0.36251655,\n",
              "           0.39667955, 0.36065117],\n",
              "          [0.18450667, 0.17041768, 0.23597562, ..., 0.3073706 ,\n",
              "           0.33007297, 0.2886588 ],\n",
              "          [0.11865286, 0.08438158, 0.14235184, ..., 0.23049203,\n",
              "           0.19399527, 0.1687754 ]],\n",
              "\n",
              "         [[0.17737672, 0.19163033, 0.2005928 , ..., 0.26268458,\n",
              "           0.2766465 , 0.31634232],\n",
              "          [0.29830328, 0.31381756, 0.3306379 , ..., 0.49654916,\n",
              "           0.49794877, 0.5221173 ],\n",
              "          [0.3659795 , 0.36787578, 0.40059802, ..., 0.6156418 ,\n",
              "           0.6036498 , 0.61926055],\n",
              "          ...,\n",
              "          [0.39446682, 0.397726  , 0.43276823, ..., 0.6627832 ,\n",
              "           0.63978225, 0.65218997],\n",
              "          [0.32287797, 0.31270638, 0.36736012, ..., 0.56118816,\n",
              "           0.5290647 , 0.52710956],\n",
              "          [0.1899996 , 0.19747578, 0.22361001, ..., 0.36661464,\n",
              "           0.3119128 , 0.29144162]],\n",
              "\n",
              "         [[0.22238876, 0.23485494, 0.26088566, ..., 0.37232593,\n",
              "           0.3518301 , 0.3857615 ],\n",
              "          [0.38592204, 0.39023802, 0.4359549 , ..., 0.66783535,\n",
              "           0.6296978 , 0.65289414],\n",
              "          [0.47327438, 0.4753215 , 0.53198725, ..., 0.81120193,\n",
              "           0.77102876, 0.78732914],\n",
              "          ...,\n",
              "          [0.49857628, 0.5193242 , 0.568089  , ..., 0.85927933,\n",
              "           0.80384207, 0.8250404 ],\n",
              "          [0.41599035, 0.4043943 , 0.47743836, ..., 0.7246918 ,\n",
              "           0.65781116, 0.6761491 ],\n",
              "          [0.24550277, 0.27269393, 0.28325492, ..., 0.44341165,\n",
              "           0.39221537, 0.3862703 ]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[0.21283096, 0.18916465, 0.23723465, ..., 0.38902798,\n",
              "           0.31690887, 0.3426907 ],\n",
              "          [0.35937226, 0.359368  , 0.3989472 , ..., 0.64456534,\n",
              "           0.5694539 , 0.6018358 ],\n",
              "          [0.43969625, 0.44706574, 0.47897038, ..., 0.7613317 ,\n",
              "           0.7014773 , 0.7209348 ],\n",
              "          ...,\n",
              "          [0.43623263, 0.46088055, 0.48071814, ..., 0.76306903,\n",
              "           0.7062397 , 0.72110975],\n",
              "          [0.36219272, 0.37011823, 0.4008566 , ..., 0.63784206,\n",
              "           0.5740793 , 0.60307527],\n",
              "          [0.2126505 , 0.2585828 , 0.2437393 , ..., 0.38077894,\n",
              "           0.35064736, 0.3505236 ]],\n",
              "\n",
              "         [[0.17057858, 0.14144038, 0.16252972, ..., 0.313398  ,\n",
              "           0.24899173, 0.28505698],\n",
              "          [0.29070464, 0.28986338, 0.2981707 , ..., 0.5243607 ,\n",
              "           0.45810238, 0.5073285 ],\n",
              "          [0.3658502 , 0.37425047, 0.36642596, ..., 0.6289928 ,\n",
              "           0.5713276 , 0.6123255 ],\n",
              "          ...,\n",
              "          [0.36245087, 0.4219181 , 0.3834942 , ..., 0.6453592 ,\n",
              "           0.5980331 , 0.62422943],\n",
              "          [0.30922824, 0.34418598, 0.32707947, ..., 0.55361557,\n",
              "           0.4918246 , 0.5348744 ],\n",
              "          [0.17632772, 0.26177245, 0.20807196, ..., 0.3296824 ,\n",
              "           0.30338052, 0.30802086]],\n",
              "\n",
              "         [[0.08578831, 0.07687246, 0.09616549, ..., 0.2229061 ,\n",
              "           0.15954156, 0.16828315],\n",
              "          [0.15266751, 0.17882203, 0.16897178, ..., 0.3298755 ,\n",
              "           0.26867607, 0.281299  ],\n",
              "          [0.18963757, 0.23001485, 0.21100514, ..., 0.3897657 ,\n",
              "           0.34646034, 0.33593953],\n",
              "          ...,\n",
              "          [0.19605848, 0.26978064, 0.22505091, ..., 0.40138596,\n",
              "           0.3701515 , 0.34716865],\n",
              "          [0.18130386, 0.22112317, 0.18180421, ..., 0.33639976,\n",
              "           0.28145245, 0.29338592],\n",
              "          [0.09850853, 0.18704943, 0.12587187, ..., 0.16439174,\n",
              "           0.17918451, 0.17767225]]]]], dtype=float32)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred=cnn.predict(test)\n",
        "y_pred"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "475ec4b6363fc2460192c3aeb6c516f3ff16c4c7d48684e503009e7cba445f44"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
